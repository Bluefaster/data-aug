{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa67b8d0-f013-4ba0-a615-12247bfc9ac7",
   "metadata": {},
   "source": [
    "# Model Prototyping\n",
    "\n",
    "Building the basis for our model experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753b036f-c5b8-44cc-a653-4712b3b19d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "\n",
    "from torch.utils import data\n",
    "from torch.nn import Conv2d, AvgPool2d, ReLU, Dropout, Flatten, Linear, Sequential, Module\n",
    "from torch.optim import Adam\n",
    "from time import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "MODELS_DIR  = '/home/cxw/sonos_rirs/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e62a78-bba4-453b-9961-dba6aa7ba962",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "model_dict['name'] = \"testrun2_regularization\"\n",
    "model_dict['notes'] = \"same as test run but with regularization\"\n",
    "model_dict['data_path'] = '/home/cxw/sonos_rirs/features/080122_5k_phase/feature_df.csv'\n",
    "model_dict['model_path'] = os.path.join(MODELS_DIR, model_dict['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789d403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # 尝试导入IPython\n",
    "    from IPython import get_ipython\n",
    "    # 检查是否在IPython环境下\n",
    "    if get_ipython() is not None:\n",
    "        # 加载autoreload扩展\n",
    "        %load_ext autoreload\n",
    "        # 设置autoreload为2\n",
    "        %autoreload 2\n",
    "except ImportError:\n",
    "    # 如果IPython没有被安装，则不作任何操作\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e13f9ea-8e81-447e-b228-3c1fa0b22de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %autoreload 2\n",
    "# # import volume_estimation.modeling as model_funcs\n",
    "# model_funcs.train_model(model_funcs.Baseline_Model, model_dict,\\\n",
    "#                         overwrite=True, epochs=10,log=False) #######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "723b0f82-6ce6-489f-9c5a-10161015d33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32000it [00:19, 1612.05it/s]\n"
     ]
    }
   ],
   "source": [
    "feat_df = pd.read_csv(model_dict['data_path'])\n",
    "model_path = os.path.join(MODELS_DIR, model_dict['name'])\n",
    "\n",
    "dataset = []\n",
    "\n",
    "    \n",
    "def create_dataloader(feature_df, batch_size=1, log=True):\n",
    "    dataset = []\n",
    "    for row in tqdm(feature_df.iterrows()):\n",
    "        feat_file = row[1]['file_feature']\n",
    "        loaded = np.load(feat_file)\n",
    "\n",
    "        feature = loaded['feat']\n",
    "        feature = feature.reshape((1, feature.shape[0], feature.shape[1]))\n",
    "        feature = np.real(feature)\n",
    "\n",
    "        vol = loaded['vol']\n",
    "        if log:\n",
    "            vol = np.log10(vol)\n",
    "        dataset.append((feature, vol))\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "dataloader = create_dataloader(feat_df, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c987b41d-7f00-41cc-bb96-c6fdedc585f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name testrun2_regularization\n",
      "notes same as test run but with regularization\n",
      "data_path /home/cxw/sonos_rirs/features/080122_5k_phase/feature_df.csv\n",
      "model_path /home/cxw/sonos_rirs/models/testrun2_regularization\n"
     ]
    }
   ],
   "source": [
    "savename = './testmodeldict.json'\n",
    "with open(savename, 'w') as f:\n",
    "    json.dump(model_dict, f)\n",
    "    \n",
    "with open(savename) as f:\n",
    "    load_dict = json.load(f)\n",
    "    \n",
    "for key in load_dict.keys():\n",
    "    print(key, load_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f91342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a66ab9-e949-4408-943c-ade51b8c2562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1920it [00:01, 1609.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6420it [00:03, 1607.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6380it [00:03, 1602.83it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = feat_df[feat_df['split']=='train']\n",
    "train_sample_df = train_df.sample(frac=0.1)\n",
    "val_df = feat_df[feat_df['split']=='val']\n",
    "test_df = feat_df[feat_df['split']=='test']\n",
    "\n",
    "print(\"Creating training dataloader\")\n",
    "train_dataloader = create_dataloader(train_sample_df, batch_size=128)\n",
    "\n",
    "print(\"Creating validation dataloader\")\n",
    "val_dataloader = create_dataloader(val_df)\n",
    "\n",
    "print(\"Creating test dataloader\")\n",
    "test_dataloader = create_dataloader(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f680db8-27a2-4db8-84d3-2ef287da00ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([128, 1, 30, 1997])\n",
      "Labels batch shape: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {features.size()}\")\n",
    "print(f\"Labels batch shape: {labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c776c9f2-fba2-4f0f-9ea2-93f35ecaeb4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Baseline_Model(Module):\n",
    "    def __init__(self, input_shape):\n",
    "        #accepts a tuple with the height/width of the feature\n",
    "        #matrix to set the FC layer dimensions\n",
    "        super(Baseline_Model, self).__init__()\n",
    "        \n",
    "        #block1\n",
    "        Conv1 = Conv2d(1, 30, kernel_size=(1,10), stride=(1,1))\n",
    "        Avgpool1 = AvgPool2d((1,2), stride=(1,2))\n",
    "\n",
    "        #block2\n",
    "        Conv2 = Conv2d(30, 20, kernel_size=(1,10), stride=(1,1))\n",
    "        Avgpool2 = AvgPool2d((1,2), stride=(1,2))\n",
    "\n",
    "        #block3\n",
    "        Conv3 = Conv2d(20, 10, kernel_size=(1,10), stride=(1,1))\n",
    "        Avgpool3 = AvgPool2d((1,2), stride=(1,2))\n",
    "\n",
    "        #block4\n",
    "        Conv4 = Conv2d(10, 10, kernel_size=(1,10), stride=(1,1))\n",
    "        Avgpool4 = AvgPool2d((1,2), stride=(1,2))\n",
    "\n",
    "        #block5\n",
    "        Conv5 = Conv2d(10, 5, kernel_size=(3,9), stride=(1,1))\n",
    "        Avgpool5 = AvgPool2d((1,2), stride=(1,2))\n",
    "\n",
    "        #block6\n",
    "        Conv6 = Conv2d(5, 5, kernel_size=(3,9), stride=(1,1))\n",
    "        Avgpool6 = AvgPool2d((2,2), stride=(2,2))\n",
    "\n",
    "        #dropout\n",
    "        dropout_layer = Dropout(p=0.5)\n",
    "        height5 = input_shape[0] - 2\n",
    "        height6 = (height5 - 2) // 2\n",
    "\n",
    "        time1 = (input_shape[1] - 9) // 2\n",
    "        time2 = (time1 - 9) // 2\n",
    "        time3 = (time2 - 9) // 2\n",
    "        time4 = (time3 - 9) // 2\n",
    "        time5 = (time4 - 7) // 2\n",
    "        time6 = (time5 - 7) // 2\n",
    "\n",
    "        flat_dims = 5 * height6 * time6\n",
    "        fc_layer = Linear(flat_dims, 1)\n",
    "        \n",
    "        self.net = Sequential(\n",
    "                    Conv1, ReLU(), Avgpool1,\n",
    "                    Conv2, ReLU(), Avgpool2,\n",
    "                    Conv3, ReLU(), Avgpool3,\n",
    "                    Conv4, ReLU(), Avgpool4,\n",
    "                    Conv5, ReLU(), Avgpool5,\n",
    "                    Conv6, ReLU(), Avgpool6,\n",
    "                    dropout_layer, Flatten(),\n",
    "                    fc_layer, Flatten()\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        for layer in self.net:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d4bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "679cdf44-c94c-4f28-85ef-60136ca87ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height = features.size()[2]\n",
    "input_width = features.size()[3]\n",
    "\n",
    "model = Baseline_Model((input_height, input_width)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c15e54c8-8449-4890-95ee-a5749982a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(output, target):\n",
    "    loss = torch.mean((output - target)**2)\n",
    "    return loss\n",
    "\n",
    "def Bias(output, target):\n",
    "    loss = torch.mean(torch.abs(10**output - 10**target))\n",
    "    return loss\n",
    "\n",
    "def CovStep(output, target, output_mean, target_mean):\n",
    "    loss = torch.mean(((output - output_mean) * (target - target_mean)))\n",
    "    return loss\n",
    "\n",
    "def MeanAbsLogStep(output, target, log=True):\n",
    "    #convert out of log\n",
    "    if log:\n",
    "        vol_pred = 10**output\n",
    "        vol_target = 10**target\n",
    "    else:\n",
    "        vol_pred = output\n",
    "        vol_target = target\n",
    "    loss = torch.mean(torch.abs(torch.log(vol_pred/vol_target)))\n",
    "    return loss\n",
    "\n",
    "def compute_eval_metrics(dataloader, model, log=True):\n",
    "    target_sum = 0\n",
    "    pred_sum = 0\n",
    "    n_steps = 0\n",
    "    \n",
    "    for (x,y) in dataloader:        \n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "        pred = model(x)\n",
    "        target_sum += y.sum()\n",
    "        pred_sum += pred.sum()\n",
    "        n_steps += 1\n",
    "    \n",
    "    target_mean = target_sum/n_steps\n",
    "    pred_mean = pred_sum/n_steps\n",
    "    \n",
    "    mse = 0\n",
    "    mean_error = 0\n",
    "    cov = 0\n",
    "    abs_log_ratio = 0\n",
    "    \n",
    "    var_pred = 0 #technically var * N but gets cancelled out in Pearson calculation\n",
    "    var_target = 0 \n",
    "    \n",
    "    for (x,y) in dataloader:        \n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "        pred = model(x)\n",
    "        mse += MSE(pred, y)\n",
    "        mean_error += Bias(pred, y)\n",
    "        cov += CovStep(pred, y, pred_mean, target_mean)\n",
    "        abs_log_ratio += MeanAbsLogStep(pred, y, log=log)\n",
    "        \n",
    "        var_pred += MSE(pred, pred_mean)\n",
    "        var_target += MSE(y, target_mean)\n",
    "        \n",
    "        pears = CovStep(pred, y, pred_mean, target_mean)/(torch.sqrt(MSE(pred, pred_mean))*torch.sqrt(MSE(y, target_mean)))\n",
    "    \n",
    "    out_dict = {}\n",
    "    out_dict['mse'] = (mse / n_steps).item()\n",
    "    out_dict['bias'] = (mean_error / n_steps).item()\n",
    "    out_dict['pearson_cor'] = (cov/(torch.sqrt(var_pred) * torch.sqrt(var_target))).item()\n",
    "    out_dict['mean_mult'] = (torch.exp(abs_log_ratio/n_steps)).item()\n",
    "    \n",
    "    return out_dict\n",
    "    \n",
    "# eval_dict = compute_eval_metrics(val_dataloader, model)\n",
    "# print(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca9da7-3de4-4f84-a11e-2e7f123691ac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = Adam(model.parameters(),lr=0.0005, weight_decay=1e-2)\n",
    "\n",
    "hist = {\n",
    "\t\"train_loss\": [],\n",
    "\t\"val_loss\": [],\n",
    "    \"val_bias\": [],\n",
    "    \"val_pearson_cor\": [],\n",
    "    \"val_mean_mult\": []\n",
    "}\n",
    "\n",
    "for ep in range(800):     #########################################################################                   \n",
    "    t_start = time()\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_steps = 0\n",
    "    val_steps = 0\n",
    "    \n",
    "    for (x, y) in train_dataloader:\n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "        \n",
    "        ###################################################################################################\n",
    "        # 获取批次大小\n",
    "        batch_size = x.size(0)\n",
    "    \n",
    "        # 计算需要随机选择的样本数量（25%）\n",
    "        num_samples_to_select = batch_size // 4 # 128 // 4 = 32\n",
    "    \n",
    "        # 生成随机索引\n",
    "        random_indices = torch.randperm(batch_size)[:num_samples_to_select]\n",
    "    \n",
    "        # 根据随机索引选择样本\n",
    "        x_selected = x[random_indices]\n",
    "        y_selected = y[random_indices]\n",
    "        \n",
    "        # x_selected 的形状是 [num_samples_to_select, channels, freq_dim, time_dim]\n",
    "        _, channels, freq_dim, time_dim = x_selected.shape\n",
    "    \n",
    "        # 设定掩蔽矩形块的数量和大小\n",
    "        num_blocks = 10  # 每个样本掩蔽的块数\n",
    "        block_freq_size = 5  # 频率维度的块大小\n",
    "        block_time_size = 100  # 时间维度的块大小\n",
    "\n",
    "        # 对 x_selected 中的每个样本进行掩蔽操作\n",
    "        for i in range(num_samples_to_select):\n",
    "            for _ in range(num_blocks):\n",
    "                # 随机选择块的起始位置\n",
    "                start_freq = np.random.randint(0, freq_dim - block_freq_size)\n",
    "                start_time = np.random.randint(0, time_dim - block_time_size)\n",
    "            \n",
    "                # 计算块的结束位置\n",
    "                end_freq = start_freq + block_freq_size\n",
    "                end_time = start_time + block_time_size\n",
    "            \n",
    "                # 掩蔽块\n",
    "                x_selected[i, 0, start_freq:end_freq, start_time:end_time] = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #####画图####\n",
    "        # 通常我们会取batch中的第一个样本\n",
    "        x_selected_cpu = x_selected.cpu()\n",
    "        example_spectrogram = x_selected_cpu[0, 0, :, :].numpy()\n",
    "\n",
    "        # 绘制语谱图\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(example_spectrogram, aspect='auto', origin='lower')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Spectrogram')\n",
    "        plt.show()\n",
    "    \n",
    "        # 替换原始批次中的样本\n",
    "        x[random_indices] = x_selected\n",
    "        y[random_indices] = y_selected\n",
    "        \n",
    "    \n",
    "    # 模型前向传播，获得预测值（这里使用替换后的数据）\n",
    "        ###################################################################################################\n",
    "        pred = model(x)\n",
    "\n",
    "        loss = MSE(pred, y.reshape((y.shape[0], 1)))\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        train_loss += loss\n",
    "        train_steps += 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        val_metrics = compute_eval_metrics(val_dataloader, model)\n",
    "    \n",
    "    \n",
    "    hist['train_loss'].append(train_loss/train_steps)\n",
    "    hist['val_loss'].append(val_metrics['mse'])\n",
    "    hist['val_bias'].append(val_metrics['bias'])\n",
    "    hist['val_pearson_cor'].append(val_metrics['pearson_cor'])\n",
    "    hist['val_mean_mult'].append(val_metrics['mean_mult'])\n",
    "    \n",
    "    t_end = time()\n",
    "    \n",
    "    t_elapsed = t_end - t_start\n",
    "    print(\"Epoch: {}\\tDuration: {:.2f}s\\tTrain loss: {:.4f}\\tVal loss: {:.4f}\\tVal bias:{:.4f}\\tVal Pearson correlation: {:.4e}\\tVal MeanMult: {:.4f}\"\\\n",
    "          .format(ep, t_elapsed, train_loss/train_steps, val_metrics['mse'],\\\n",
    "                  val_metrics['bias'], val_metrics['pearson_cor'],val_metrics['mean_mult']))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d51875",
   "metadata": {},
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80a23d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 创建一个空列表来存储pred和y的值\n",
    "data_to_save = []\n",
    "\n",
    "test1_df = test_df.sample(5)\n",
    "\n",
    "mae = 0.0 \n",
    "total_samples = 0\n",
    "\n",
    "test_dataloader1 = create_dataloader(test1_df) \n",
    "test_random = compute_eval_metrics(test_dataloader1,model) \n",
    "print(test_random)\n",
    "\n",
    "for(x,y) in test_dataloader: \n",
    "    (x,y) = (x.to(device),y.to(device)) \n",
    "    pred = model(x) \n",
    "    for i in range(len(pred)):\n",
    "        data_to_save.append([pred[i].item(), y[i].item()])\n",
    "\n",
    "# 指定要保存的CSV文件名\n",
    "csv_filename = 'predictions.csv'\n",
    "\n",
    "# 打开CSV文件并将数据写入\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    \n",
    "    # 写入列名（如果需要）\n",
    "    csv_writer.writerow(['Prediction', 'Actual'])\n",
    "    \n",
    "    # 写入数据\n",
    "    csv_writer.writerows(data_to_save)\n",
    "\n",
    "print(f'Data saved to {csv_filename}')\n",
    "#     print(pred,'///',y)\n",
    "\n",
    "#     # 计算绝对误差\n",
    "#     absolute_error = torch.abs(pred-y)\n",
    "\n",
    "#     # 累加绝对误差和样本数\n",
    "#     mae += absolute_error.sum().item()\n",
    "    \n",
    "\n",
    "# #     计算平均绝对误差\n",
    "\n",
    "\n",
    "# mae /= 5 \n",
    "# print(\"MAE:\", mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb35a4-183c-43d8-ab9a-00adaba3bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    eval_test = compute_eval_metrics(test_dataloader, model)\n",
    "    print(eval_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde495a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6dd632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cxwnotebook",
   "language": "python",
   "name": "cxwnotebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
